# redis的应用场景

1.可以先说一下5个类型

String：位图（官方给的场景是记录登陆天数）

List：类似于java中的ArrayDeque，同向进出表示栈，反向进出表示队列，阻塞获取可以做阻塞队列，直接用索引获取可以做数组

Set：可以做抽奖（可重复的抽奖或者不可重复的抽奖都可以做），可以做字典

SortSet：可以做排名

Hash：可以存储复杂对象

2.在项目中的使用，主要用于缓存

①分布式锁：在WRMS中，billing与lre模块都需要对vehicle trip表进行一个修改，所以要加入分布式锁防止数据在同一时间被两个服务同时访问修改

②存储token信息：在WRMS中，登陆的时候，我们会将token保存起来作为key，用户对象作为value，设置为半小时过期，然后当前端用户进行请求的时候要带token进行请求，用拦截器进行拦截，验证当前用户是否登陆

# redis是单线程还是多线程

要分情况讨论，redis的工作线程是单线程的，当然也包含其他线程，在新版本的redis中，支持了IO多线程（目的是提高吞吐量）

（单线程，满足redis原子计算的前提下，将IO放到多个线程中进行执行，执行的时候IO是并行读取数据，放入到堆中，然后并行输出数据，只有中间的计算是串行执行，好处是充分压榨CPU资源，提高吞吐量）

# redis中的原子操作

1.lua脚本

2.pipeline管道

3.redis事务在发送到redis客户端并堆积的过程并不是原子的，只有在执行的时候是原子的（执行的时候出现错误，就直接继续执行下一条指令，不会回滚（redis作者说：我们认为这是正常的）（少用事务））

# redis存在线程安全吗？为什么？

1.如果从客户端角度的话，确实存在线程安全问题，由于网络等问题，可能先发后置，导致redis先处理后面发过来的请求

2.在redis自己来看，不存在线程安全问题，毕竟redis是单工作线程进行运算的

# 遇到过缓存穿透吗？详细描述一下

遇到过，像有些用户他根据invoice no查trip信息的时候，明明数据库中没有，但还是要经过一次查询，当然由于项目原因，我想应该没啥人那么无聊会对我们服务器进行攻击，所以偶尔的小穿透问题不大

缓存穿透产生的原因是用户查询了数据库中不存在的数据，如果有心人想要对数据库进行攻击，就可以利用这一点。

关于缓存穿透的解决方案，使用各种过滤器，包括布隆过滤器（布谷鸟过滤器）（在这两者的选择上，布隆过滤器适用于不需要删除key的情况的，因为由于布隆过滤器的算法不可逆性，没法正确删除之前key带来的影响，如果要删除key，可以使用布谷鸟过滤器，如果经常插入数据，使用布隆过滤器，如果经常查询数据，使用布谷鸟过滤器）

还有一种比较低级但是做起来比较方便的做法是使用空key

# 遇到过缓存击穿吗？详细描述一下

出于项目的问题，不算遇到，但是我知道

缓存击穿是指key在过期的时候或者某个key没被缓存过（redis当前没有缓存），数据库存在数据，突然产生很多并发请求当前key，导致并发请求直接打到数据库，严重的可能导致数据库瘫痪

解决方案：加分布式锁，热点数据不过期

（具体分布式锁的执行逻辑，并发请求到达，先请求redis，取不到数据，争抢锁，抢到了的线程进行数据库查询，查到数据后返回并设置redis的key，其他线程隔一会去看一下，然后发现查redis的时候，缓存已经存在，就不会产生击穿了）

# 遇到过缓存雪崩吗？详细描述一下

出于项目的问题，不算遇到，但是我知道

缓存雪崩是指在某个时间段，大量key过期，然后大量并发请求打入redis，redis中无缓存数据，数据库存在数据，导致缓存雪崩，请求全部落到数据库

解决方案：

1.设置key随机过期时间，让key均匀过期，不让key在某时大量过期

2.对于热点数据，可以加锁，也可以进行热点数据不过期的策略

3.缓存降级，准备一个备份缓存，备份缓存时间设置的长一点，然后如果主缓存取不到，也无法获取锁，从备份中取老旧数据返回

# redis的缓存回收机制（如何删除过期key）

redis缓存回收有两种方式，主动与被动

主动就是指：redis会开线程去定期进行随机抽样，抽样一组数据，如果有25%以上的数据都是过期的，就将这些过期内存回收，并且再取一次，如果，有25%以下过期的，那么就回收内存并且结束。

被动就是指：在redis的key被访问时，发现当前key已经过期，就进行一个内存回收

# redis是如何淘汰的？

使用淘汰策略，8种

1.不淘汰，如果内存不够就报错

2.根据当前过期集合中的过期时间长短进行淘汰，有先淘汰过期时间短的（即将过期的）

3.在当前过期集合中，用lru算法进行一个淘汰，最近最少使用的key会被淘汰

4.在当前过期集合中，用lfu算法进行一个淘f汰，最近最少使用频率的key会被淘汰

5.在当前过期集合中，随机淘汰

6.在所有集合中，用lru算法进行一个淘汰，最近最少使用的key会被淘汰

7.在所有集合中，用lfu算法进行一个淘f汰，最近最少使用频率的key会被淘汰

8.在所有集合中，随机淘汰

# 如何进行缓存预热

进行缓存预热，需要提前将热数据从db读入到缓存中，根据具体业务逻辑，尽量多加载。（可以使用线上流量监控，观察哪些是热数据）

# 数据库与缓存不一致如何解决（双写一致性问题）

可以提一嘴使用分布式事务来解决，但是这样的解决方案太重了，划不来，不提也罢

一般我们会使用cache aside pattern来解决数据不一致的问题，具体操作就是当产生更新操作的时候，先更新数据库，然后再删除掉缓存中的数据，这样操作的话缺点就是可能取到老数据（数据延迟）（当然，以上描述的操作均发生于java code中，可能出现一个问题就是mysql写入成功，然后java code服务器突然宕机，导致redis未更新，数据不一致，具体解决方案为在数据库端使用阿里的canal，伪装成一台mysql的slave，开启监听binlog，一旦binlog中有增量更新的数据，就会触发写redis的操作）

~~还有一种策略是更新数据库后更新redis，这样的话由于网络io的不确定性，可能导致先操作db的后更新，把redis数据更新错了，更加不可取~~

~~还有一种策略是删除key后更新数据库，也不可取，因为数据库写入需要的时间相对较久，那么删除key这段时间如果有其他线程取数据，依然会取到老数据，而且在老数据过期前不能再读到新数据了~~

综上还是cache aside 模式最保险一些

# 简述一下主从不一致的问题

1.redis主从同步不是强一致性的，是弱一致性的，是异步的，肯定会发生主从不一致的问题（所以锁不能用主从）

2.配置文件中可以配置min-replicas-to-write，规定最少几个从写成功，保证数据完整性

3.还可以用redis提供的wait方法保证同步个数

（2，3的解决方案都违背了redis的初衷，降低了redis的速度，所以还是不推荐使用，但是要答题就这么回答）

# 描述一下redis持久化原理

redis持久化方式分两种，AOF（append only file）和RDB（redis database），其中AOF是一个及时写，而RDB是一个快照写（还有一种非单机的，主从复制也可以算）

AOF的持久化原理如下：

> redis默认每秒都会将数据从OS内存通过fsync方法异写到磁盘（还有两种方式为 1.一直不写，直到OS buffer满了自动写 2.数据一到就写），然后等到AOF文件足够庞大的时候，会进行一个bgrewrite的操作进行文件压缩，具体操作是
>
> 1.使用fork指令开启子进程（子进程是写时复制的模式，所以父子进程之间数据变化不共享），然后进行aof文件的读取和压缩，老版本的时候，读取和压缩的策略是对可以合并的语句进行合并，对可以抵消的语句进行抵消，新版本的时候，aof结合了rdb的精华，会对当前子进程中的数据进行一个解析，并存放到磁盘上
>
> 2.此时主进程也需要做一些事情
>
> 2.1主要是要开启一个积压缓冲区，对当前接收的数据指令进行一个记录，方便等子进程的临时文件创建完毕之后将这段时间内的增量写入到文件中
>
> 2.2继续处理外部请求
>
> 2.3为了防止中途宕机，还要继续每秒向原aof文件中写入数据
>
> 3.等子进程完成后，通知主进程，主进程会拿到完成后的临时文件，再将挤压缓冲区的数据写入到文件中，最后用生成的新文件，替换老的aof文件

RDB持久化原理如下：

> 当使用bgsave方法时，进行RDB的存储
>
> 1.使用fork指令开辟子进程，获取到当前快照
>
> 2.根据当前子进程中的内容进行解析，解析完毕后放入rdb文件中
>
> 3.关闭子进程

当然RDB还有一种直接save的方式，即不调用bgsave指令，调用save指令，会进行服务阻塞，不再向外提供服务，然后安安心心的写入磁盘

# Redis挡不住请求，流量打到DB如何处理？

参考缓存雪崩，击穿和穿透的解决方案

开启redis集群，将键散乱分部在不同的机器上，这样就算某一台redis挂了，也只会产生那台所接收的key小部分丢失问题

# Redis事务的三条指令，如果事务出问题，那么如何处理

MULTI ，EXEC ，WATCH 

如果事务出问题，那么之前执行的也就执行了，不会进行回滚，会接着执行后面的语句

（ps：watch主要就是监控key的变化，在进行exec正式执行的时候，会去对比watch的key，看看是否产生变化，有点CAS的感觉，如果产生变化，那么就不执行了，类似于回滚的感觉）

# redis实现分布式锁

实现分布式锁需要实现加锁和解锁方法

1.加锁

①我们可以使用set方法进行一个原子上锁，上锁的同时判断当前是否有锁，并且设置锁的过期时间，以防止当前服务宕机导致死锁

②然后在上锁过程中，可以开启守护线程，对锁进行一个加时处理，每隔一段时间就去重置锁的过期时间，防止任务未完成，锁就失效了

③可以将值设置为当前线程id+次数以达到可重入锁的效果（这条有问题的，网上解释都是错的，根本实现不了可重入锁的操作，所以安安心心就说分布式锁就好了）

2.解锁

由于解锁需要查询当前key是否存在并进行删除，两个动作，所以不能分开执行，要原子执行，所以要使用lua脚本进行逻辑编写，具体lua脚本上的操作就是检查一下当前锁是否存在并且解锁线程是否为当前线程，且数值是否降为0，如果降为0，就进行锁删除

# 杂项

想一下为什么要有对应的缓存穿透，击穿和雪崩的解决方案，因为数据库是整个架构的瓶颈，不管多少请求，最终都是要进入数据库进行修改的，数据库的压力会非常的大。为了解决这个瓶颈，才会产生对应的解决方案，只让有效请求落到数据库，减少无效请求，占用数据库的资源