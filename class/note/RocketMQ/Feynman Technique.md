# MQ选用问题

## 使用的什么MQ？

RocketMQ

## 有什么好处？

**解耦**

服务解耦，服务之间相互调用产生了强依赖关系，如果服务a调用服务b，需要服务b的返回，那么服务b一旦下线，会直接导致服务a不可用，使用MQ解决了这一问题，通过将数据先放到MQ中，然后直接返回给服务a成功的信息

**异步**

微服务之间的调用如果不使用MQ，直接调用，等待其他服务的返回，就会产生同步调用，网络是不可控的，有可能由于网络原因导致响应时间过长，加入了MQ之后就可以进行异步调用了，先把数据放入MQ中，等待后续的consumer进行消费

**削峰**

每个时间段数据的流量不一致，有可能在某个时间段数据特别多，服务器需要做一个限流削峰的操作，来防止服务器响应过慢或者被击瘫，如果服务器能够支撑的流量小于到达的流量，做了限流可能会产生数据丢失，需要MQ对数据进行一个暂存，让consumer可以均匀的消费数据

## 关于MQ的选型？

市面上常见的MQ有ActiveMQ，RocketMQ，RabbitMQ还有Kafka，正常来说，如果数据体量小，选用ActiveMQ，不然的话选其他三种，其他三种综合来讲差不太多，主要看项目组的熟悉程度，选用大家都熟悉的MQ进行开发，然后后三种也有一些小区别，比如说RabbitMQ由于Erlang的语言的天然优势，天然支持分布式的，所以RabbitMQ响应速度较快，延迟较低，但是RocketMQ和Kafka吞吐量相对高一点，RocketMQ是用Java写的，对于开发人员来说更加熟悉，做定制化更加的简单，RocketMQ使用相对方便，提供了一些电商所需要的的api，比如说顺序消费，Kafka的吞吐量是最高的，Kafka给自己的初始定位就是处理数据体量较大的情况，它同时使用了mmap和sendfile两张零拷贝技术，对于大数据的处理是比较快速的，但是使用时要开发自己的api

# RocketMQ由哪些角色组成，作用和特点是什么？

RocketMQ主要由4个角色组成，分别是nameserver，broker，consumer和producer

首先是nameserver，是一个注册中心的功能，底层使用netty实现，它的特点是一个无状态服务器，无状态服务器的意思是指它不会持久化状态，所有状态都存储在内存中。nameserver存放的是路由消息，可以通过topic找到对应的broker。它可以构成nameserver集群，不过各个nameserver之间是互不通讯的，新的nameserver上线后，broker可以通过动态列表来感知

然后是broker，broker是一个消息的存储区域，用来存放具体的消息的服务器

然后是consumer，是消费者，消费消息的

然后是producer，是生产者，向broker中生产消息的

## RocketMQ中的Topic和ActiveMQ的Topic有什么区别？

因为RocketMQ没有遵循jms协议，所以它的topic的定义与ActiveMQ中有所不同，它的topic是一个逻辑上的概念，而ActiveMQ中的Topic是一个物理上的概念，ActiveMQ中的Topic表示这个消息是一个广播消息，而RocketMQ中的Topic内部包含了一组Queue，通过Topic将Queue存放在不同的broker中，做负载均衡，是否是广播消息决定于consumer的消费模式

### Topic的结构

Topic的结构是有多个Queue（队列）组成的

# RocketMQ Broker中的消息消费后会立即删除吗？

不会，consumer的消费进度存储在本地（Broadcast模式），consumer的消费进度存储在broker中（Cluster模式），broker中收到消息之后会进行持久化，持久化到本地的CommitLog中。

**关于消息的删除**

默认是要超过设定的时间（4.6版本后48小时）才会删除不活跃的CommitLog（指最后一次使用时间到现在超过48小时），可以指定时间删除，默认凌晨4点

# RocketMQ消费模式有几种？

有两种，一种是Cluster模式，一种是BroadCast模式

Cluster模式中，以group name分组，拥有同一个groupname的consumer为一组，一组中的consumer消费同一个topic，找到topic下面对应的queue，根据负载均衡策略针对queue中内容进行一个消费，消费进度存储在broker中

BroadCast模式中，在同一个group name中的consumer都会收到同样的消息，消息消费进度由consumer本地维护

## 消费消息时使用的是pull还是push？

创建消费者的时候可以选择，但是实际上还是使用的pull，push的内部依然是使用pull去取数据

使用push的时候更多的属性已经封装完成，而pull的时候可以自定义抓取逻辑，不需要手动抓取

## 为什么要主动拉取消息而不使用事件监听？

主要原因是因为主动拉取消息，可以根据消费者自身的消费能力去拉取消息，不会导致消息拉取过来消费不了，或者消费速度很慢，给消费者的压力较大。如果使用事件监听，由broker去定时发送消息，就会导致消费者可能无法快速处理发过来的消息，还有一点就是broker的压力会变大，要开定时任务去发送消息

## consumer拉取数据的机制

consumer会开启一个长轮询进行数据拉取，consumer向broker发送请求，broker中如果有数据就返回，没数据就挂起，等到有数据才继续返回

# 常见的消息同步机制？

在4.5之前，使用异步写入，或者同步双写

在4.5之后，使用Dledger类来实现数据同步，Dledger类实现了raft协议的数据同步机制

# broker是如何处理拉取请求的？

1.接收到consumer的拉取请求，如果有数据直接返回数据

2.接收到consumer的拉取请求，如果没有数据，挂起请求

  开启线程，每隔1s根据offset查询CommitLog中有没有新的消息，如果有的话将消息写入pullRequestTable，开启线程，每5s一次（如果开启了长轮询，每5秒一次，如果开启短轮询，每隔1s一次）查询pullRequestTable中是否有数据，如果有立即推送。

# RocketMQ如何做负载均衡

producer端默认的发送策略是随机发送到对应broker中的某个queue中，如果要做负载均衡，要使用mqadmin提前进行queue的规划，然后写代码的时候规划好向哪些queue中写入对应的消息，以达到producer端的负载均衡，对应queue的选择可以使用MessageQueueSelector进行选择，默认有hash方式的，有机房发送方式的，随机发送方式的，MessageQueueSelector是producer在向nameserver获取路由数据的时候，将接收到的信息进行加工获得的

consumer端默认的接收消息的负载均衡策略是平均分配，除了这个之外，还可以选择环形分配，手动分配，机房分配（就近机房、指定机房），一致性哈希等策略进行负载均衡，最好是queue的倍数或者相等，防止消息倾斜

# RocketMQ的消息堆积如何处理

消息堆积可能原因是消费端出问题，没法处理消息了，也可能是producer端业务量增大了，原本的consumer来不及消费了

针对以上两种情况，各有不同的解决方案：

对于第一种，消费端出的问题，就要检查是不是消费端消费不了某些数据，可能要进行重启操作，重启的时候，新上线一些consumer，将consumefromwhere设置成last，保证处理新来的消息，并且通过offset去判断老的consumer是否已经消费到消费过的消息了，防止消息的重复消费。

或者重启的时候，可以新开启一个consumer，做一个消息移动，不处理业务逻辑，将堆积的消息移动到另外一个topic上面，然后开启一组consumergroup，去消费对应topic底下的数据

对于第二种，producer端出的问题，那就消息拉取速度太慢，可以多加consumer或者使用pull方法，增加指定拉取的数量，配置一次处理消息的数量，适当增加consumer的并发线程数，还可以修改producer和consumer使用的负载均衡策略

## 堆积的消息会过期吗？

单条消息不会，但是commitlog会过期

## 怎么观察到消息堆积

可以在console中配置

# 保证消息不丢
producer发送消息的时候，如果消息由于网络原因发送失败，或者有异常没有发送成功，producer会对消息进行一个重投

broker接受到消息之后会进行一个持久化，持久化到磁盘上，然后broker还可以做主从复制，如果broker宕机，可以使用Dledger来保证高可用，实现自动故障恢复，然后让slave变成broker，并且slave与master之间数据是一致的，使用了raft协议的一致性算法同步数据

consumer端接受消息会返回ack，如果没有返回，broker端也会进行一个消息的重投递

对于网络攻击，还内置了tls，使用crc32算法来校验数据

# 如果让你来动手实现一个分布式消息中间件，整体架构你会如何设计实现?

首先MQ最主要的就是中间的调度者，要在调度者上实现一个磁盘存储，持久化保证数据的可靠性，一般的话借助操作系统的的0拷贝api可以实现一个磁盘上的快速读写。

然后解决单点问题，做主从复制，设计分布式系统，解决存储容量问题，缓解服务器压力，遵循AKF原则。

# 看过RocketMQ 的源码没有。如果看过，说说你对RocketMQ 源码的理解?

看过，看的时候发现几乎所有的业务逻辑都是依赖于定时任务来完成的，开了很多很多的线程去处理业务逻辑，看起来不像外国人写的代码一样用了很多设计模式，但是没有注释，不便于观看。

对源码的理解的话具体是四个部分，producer，consumer，broker和nameserver。

nameserver的话底层是用netty实现的，所以启动的时候会用netty的api，然后会开定时任务进行无效连接的处理，比如每10秒一次清除2分钟以上没发心跳的broker，还有处理心跳包的线程，broker给nameserver发送的心跳包内容有对应的topic还有brokerId，brokerName等

然后是broker，broker的话也是会起很多定时任务，比如每30秒向nameserver发送心跳，还有进行刷盘的时候，是10ms进行一次commitlog的写入，1s进行一次consumer queue的写入，5s进行一次消息消费进度的更新，10s进行一次类过滤器的更新。然后接收consumer的获取数据的请求的时候，会以长轮询或者短轮询的方式进行处理，长轮询是间隔5s执行一次，短轮询是间隔1s执行一次，具体的动作是查看当前pushTable中是否有数据，如果有，那么就推送，如果没有，就挂起等待，然后还会开启另外一个线程每秒通过offset去检查是否有新的commitlog，如果有，就会写到pushTable中

然后是producer的定时任务是每30秒维护与broker的心跳，每30s向nameserver拉取数据，更新topic和broker信息

consumer的话如果没有设置nameserver的话会去取动态的nameserver，每2分钟一次，也会每30秒维护与broker的心跳，并且清理断线的broker，每30s向nameserver拉取数据，还会维护消费进度，如果是集群模式就是发消息到broker，如果是广播模式就是更新本地。会有个线程专门根据消费策略做消息的分配，每10s一次。使用长轮询的方式去获取数据

# 高吞吐量下如何优化生产者和消费者的性能?

对于生产者来说，可以使用批量写入

对于消费者来说，有两个参数可以设置，一个是设置单次拉取的数量，默认只有1，还有一个是单次处理的msg数量，默认32，当然，也可以增加消费者的线程数量，但是顺序消费的情况下无法这样做

因为写入的时候顺序写入，消费的时候随机读取，所以使用好的ssd也是保证性能的一种方式

# 再说说RocketMQ 是如何保证数据的高容错性的?

当producer向broker发送数据的时候，是轮询queue进行一个发送的
如果数据未被收到，producer会进行消息的重投，会根据容错策略进行重投队列的选择，如果未开启情况下，重试的时候过滤失败的broker，在开启的情况下，会判断选择的队列所在broker是否可用，不可用就发给其他broker中的queue，可用就用原来的

## 如何判断一个broker是否可用
发送消息的时候记录一下调用时间和是否报错，如果报错的话会导致当前broker在600000ms后才可用，根据时间去预测broker可用时间

## 优雅关闭broker
先清除broker的写权限，然后过段时间再关闭broker，不会产生发送失败的情况，因为30s发送心跳的时候已经把broker状态改成无法写入，所以根据容错策略，producer不会再向其中写入数据了，那么就不会产生发送失败了

# RocketMQ很大的一个特点是对分布式事务的支持，你说说他在分布式事务支持这块机制的底层原理?

分布式事务有很多种方式可以实现，市面上常见的分布式理论有2pc，3pc，tcc等，rocketmq的底层分布式事务的实现类似于2pc，它使用了半消息的概念，客户端在处理一组事务时，先将半消息发送给broker，然后broker返回OK并将其存入半消息队列中，没有实际的存放在需要放入的topic中，此时消息处于无法消费状态，然后客户端继续处理自己的业务逻辑，等到客户端事务执行结束时，客户端发送一条消息给broker，broker收到后才会将消息从半消息队列中移入到真正对应的topic中，消费者才可以消费这条消息，这就是分布式事务的底层原理

另外，如果长时间未收到客户端的返回，那么broker会开启一条线程去检测当前事务是否完成，如果未完成，就过段时间再查看一下，如果已完成，看完成的状态，来决定是否需要回滚或者放入到真正的topic中

# 堆积的消息会不会进死信队列？

不会，消息在消费失败后会进入重试队列（%RETRY%+consumergroup），多次（默认16）才会进入死信队列（%DLQ%+consumergroup）

# 顺序消费的应用场景
**binlog同步**
其他很少，因为其他的话一般会使用分布式事务进行一个处理
